{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sRSyQpK5QC-B",
   "metadata": {
    "id": "sRSyQpK5QC-B"
   },
   "source": [
    "# Exercise 2: Interactive Segmentation\n",
    "\n",
    "Your tic-tac-toe championship was a major success and everyone is waiting for the next event from you.\n",
    "Meanwhile, some curious eyes have also noticed the impressive compression algorithm you developed.\n",
    "Among them is a group of budding entrepreneurs who are working on a noble mission: to empower everyone to make their own *Cat Memes*.\n",
    "Specifically, they are developing an app where you can take a photo of your cute cat, segment it out, and paste it on any background to design your own meme.\n",
    "Crucially, the users only have to create a few scribbles, which mark the foreground (the cat) and background of the image.\n",
    "As none of the founders are Computer Vision engineers, they have approached you to develop the segmentation algorithm for the app.\n",
    "An overview of the desired pipeline is shown below.\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1AyQIlnBRmQjbHquCQVDYdCO4m9UCLDqX)\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "**Details about the setup**\n",
    "* For each test sample, the algorithm is provided a triplet consisting of the RGB image, the foreground (FG) scribble and the background (BG) scribble.\n",
    "We denote this triplet as a *sample*.\n",
    "* FG scribble is a grayscale image, where white pixels (255) are guaranteed to belong to the foreground (cat).\n",
    "* BG scribble is a grayscale image, where white pixels (255) are guaranteed to belong to the background.\n",
    "* The RGB image is a discrete image of 3 channels. Each pixel in these images is an integer which can take values between [0, 255]\n",
    "* All images of a sample have the same size. However, note that RGB images from two different samples may have different sizes.\n",
    "\n",
    "Given an input sample, your algorithm should output a single channel segmentation mask, of the same height and width as the input images.\n",
    "The output should be a boolean NumPy array (dtype `bool`) with values `True` for the foreground (cat) and value `False` for the background regions.\n",
    "In order to design your segmentation algorithm, we provide a validation dataset of 10 samples including ground truth segmentations.\n",
    "</br>\n",
    "\n",
    "\n",
    "**Evaluation Criteria**\n",
    "\n",
    "Your algorithm will be evaluated using the Intersection-over-Union (IoU) metric.\n",
    "Given the ground truth mask $A$ and the predicted mask $B$ for a sample, the metric computes (for exact details check the function `compute_iou()` inside `utils.py`)\n",
    "\n",
    "$$\n",
    "\\text{IoU} = \\frac{A \\cap B}{A \\cup B}\n",
    "$$\n",
    "\n",
    "If you follow the suggested approach, the final algorithm will be stochastic.\n",
    "To report a trustworthy score, the evaluation will be run multiple times with different random seeds. The final score is obtained as average IoU over all test images and all random seeds.\n",
    "\n",
    "\n",
    "**Passing requirement**\n",
    "\n",
    "Your algorithm will be evaluated using an online evaluation server on a hidden test set.\n",
    "In order to pass the exercise, you need to obtain an EvaluationScore of **greater than $0.59$** on the test set.\n",
    "Additionally, your segmentation algorithm should be reasonably fast, that is, segment each sample in less than 5 seconds.\n",
    "Otherwise your score will automatically be set to 0.\n",
    "The ranking on the leaderboard is obtained using only the EvaluationScore.\n",
    "\n",
    "Follow the steps in the rest of the notebook to generate the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5f6bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 10031,
     "status": "ok",
     "timestamp": 1760607087347,
     "user": {
      "displayName": "Georg Brunner",
      "userId": "13067529464681546142"
     },
     "user_tz": -120
    },
    "id": "58d5f6bd"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# These two lines ensure that we always import the latest version of a package, in case it has been modified.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-z25K7OrXwLO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1729168434916,
     "user": {
      "displayName": "IACV-TA-Team",
      "userId": "02056513601283280926"
     },
     "user_tz": -120
    },
    "id": "-z25K7OrXwLO",
    "outputId": "74dd73b9-df55-4ff7-a88d-20cd46876df1"
   },
   "outputs": [],
   "source": [
    "# Mount your drive and set the correct path\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I0YBdw2nYW_p",
   "metadata": {
    "id": "I0YBdw2nYW_p"
   },
   "source": [
    "**TODO:** Set the path in Google drive where you uploaded the handout, e.g. MyDrive/iacv/ex2 </br>\n",
    "**NOTE:** Even if your drive is set to a different language - always start the path with MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mfizt1rCYODg",
   "metadata": {
    "id": "mfizt1rCYODg"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "iacv_path = 'MyDrive/...'\n",
    "\n",
    "env_path = Path('/content/drive') / iacv_path\n",
    "data_path = env_path / 'data'\n",
    "\n",
    "# Add the handout folder to python paths\n",
    "if str(env_path) not in sys.path:\n",
    "    sys.path.append(str(env_path))\n",
    "\n",
    "# Now we can import our other files\n",
    "from utils import (\n",
    "    compute_iou,\n",
    "    evaluate_segmentation,\n",
    "    load_sample,\n",
    "    show_sample\n",
    ")\n",
    "\n",
    "from image_segmenter import ImageSegmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521beef",
   "metadata": {
    "id": "8521beef"
   },
   "source": [
    "## Visualise random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa47c49",
   "metadata": {
    "id": "6fa47c49"
   },
   "outputs": [],
   "source": [
    "# Go through 'val' folder and get names of subdirectories - one subdir is one sample\n",
    "sample_dirs = [dd for dd in data_path.iterdir() if dd.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360dd3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 1774,
     "status": "ok",
     "timestamp": 1729168442432,
     "user": {
      "displayName": "IACV-TA-Team",
      "userId": "02056513601283280926"
     },
     "user_tz": -120
    },
    "id": "a360dd3a",
    "outputId": "907e18ba-c41e-484d-d56a-300db0fd0cce"
   },
   "outputs": [],
   "source": [
    "sample_path = data_path / '04'\n",
    "sample_dd = load_sample(sample_path)\n",
    "show_sample(sample_dd, show_scribble=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WmdLPbtOjOiC",
   "metadata": {
    "id": "WmdLPbtOjOiC"
   },
   "source": [
    "## Implement your solution\n",
    "\n",
    "You are provided with a simple implementation of the `ImageSegmenter` class (`image_segmenter.py`).\n",
    "The `ImageSegmenter` class is responsible to generate a segmentation mask, given a sample.\n",
    "Modify this class to include your algorithm.\n",
    "\n",
    "The rest of the exercise will roughly explain how the baseline solution was implemented.\n",
    "If you follow the descriptions, implement the missing bits and tune some hyperparameters you will have no problem passing this exercise.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* Having said that, you are free to implement whichever algorithm you fancy - as long as you do not use external packages and beat the baseline, anything is allowed.\n",
    "* You are not allowed to use any external packages except the ones already imported in `image_segmenter.py`. Otherwise your submission will crash on the Evaluation server.\n",
    "* You might want to first check out how the `ImageSegmenter` class will be used, before implementing.\n",
    "Have a look at the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe801591",
   "metadata": {
    "id": "fe801591"
   },
   "source": [
    "### K-means clustering and KNN classification\n",
    "\n",
    "The FG/BG scribble masks provide us with locations in the image, which correspond to foreground/background respectively.\n",
    "We can use these masks to perform segmentation as follows:\n",
    "1. In a first step we extract all pixels intensities of foreground only.\n",
    "We can then use a clustering algorithm, such as k-means, to create $k_1$ visual words, which \"summarise\" these foreground pixels.\n",
    "2. The same can be done for background pixels using $k_2$ clusters.\n",
    "3. With k-means we have now extracted two sets of cluster centroids: The first $k_1$ centroids represent a model of foreground pixels, while the other $k_2$ centroids correspond to background pixels.\n",
    "4. We can now predict the label of any other pixel in the image using nearest neighbor classification: If the closest of all $k_1 + k_2$ centroids came from the foreground clusters, the pixel is labeled foreground - otherwise background.\n",
    "\n",
    "What you have to do:\n",
    "* Implement the k-means clustering algorithm.\n",
    "The file `kmeans.py` provides a starting point.\n",
    "* Implement the kNN classifier (no need to cover k > 1). Again the file `kmeans.py` provides a starting point.\n",
    "* Implement the method `segment_image_kmeans()` of the `ImageSegmenter` class. Here you have to combine the two algorithms in order to segment FG/BG with the strategy outlined above.\n",
    "\n",
    "The following image shows a segmentation, that has been created with this approach.\n",
    "Note how the prediction is noisy and dark parts of the background are often mistaken to be foreground.\n",
    "\n",
    "</br>\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=15hG1Atv_En0A0df0QTRU3i1P4dqRcoP9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "s8JOhPOjduAs",
   "metadata": {
    "id": "s8JOhPOjduAs"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This code tests your k-means implementation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkmeans\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kmeans_fit, check_kmeans\n\u001b[32m      4\u001b[39m check_kmeans(kmeans_fit, data_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tovon\\IACV\\ex2_segmentation\\kmeans.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_sample\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# This code tests your k-means implementation\n",
    "from kmeans import kmeans_fit, check_kmeans\n",
    "\n",
    "check_kmeans(kmeans_fit, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kp-KIetndunh",
   "metadata": {
    "id": "kp-KIetndunh"
   },
   "outputs": [],
   "source": [
    "# This code tests your kNN implementation\n",
    "from kmeans import kNN, check_kNN\n",
    "\n",
    "check_kNN(kNN, display_prediction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470dedf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1729168636924,
     "user": {
      "displayName": "IACV-TA-Team",
      "userId": "02056513601283280926"
     },
     "user_tz": -120
    },
    "id": "7470dedf",
    "outputId": "c2d94509-48c6-49b4-c1f3-f9027f465704"
   },
   "outputs": [],
   "source": [
    "# Run your segmentation algorithm\n",
    "segmenter = ImageSegmenter(k_fg=2, k_bg=5, mode='kmeans')\n",
    "\n",
    "mask_pred = segmenter.segment_image(sample_dd)\n",
    "\n",
    "iou_score = compute_iou(\n",
    "    sample_dd['mask_true'].astype(bool),\n",
    "    mask_pred.astype(bool)\n",
    ")\n",
    "\n",
    "# Visualize your prediction\n",
    "show_sample(sample_dd, mask_pred=mask_pred)\n",
    "print(f'IoU score is: {iou_score:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kKV79-9Oe9ny",
   "metadata": {
    "id": "kKV79-9Oe9ny"
   },
   "source": [
    "### Including more features\n",
    "\n",
    "Until now, the prediction of a pixel's class was purely based on the intensity of said pixel alone. At this point we can think of other features, that might be useful for our prediction task.\n",
    "An easy feature to add is the pixels position coordinates. You should see an improvement upon adding this information to the k-means, k-NN pipeline.\n",
    "\n",
    "Can you think what kind of prior about the segmentation this correcponds to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2XC31cmoe_G5",
   "metadata": {
    "id": "2XC31cmoe_G5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "z8FJcKoqfB6E",
   "metadata": {
    "id": "z8FJcKoqfB6E"
   },
   "source": [
    "### Extract patches\n",
    "\n",
    "**Note:**</br>\n",
    "The following task is optional for Exercise 2. You should not need to implement this to pass the baseline. However for Exercise 3, we will require the patch extraction function described below. Therefore you can already start implementing this function now in order to reduce the workload later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77699a2",
   "metadata": {
    "id": "e77699a2"
   },
   "source": [
    "Other possible features could be included by considering neighborhood information around a given pixel, eg. intensities of a small patch centerd at the pixel in question.\n",
    "\n",
    "To this end, we now aim to extract all possible patches from the image.\n",
    "That is for every pixel in the image we want to extract it's p x p neighborhood.\n",
    "This neighborhood can later be used as feature for prediction.\n",
    "\n",
    "A naive implementation of this patch extraction will be way too slow!\n",
    "There is a way to do this rather efficiently with the help of NumPy's roll() function.\n",
    "The below image shows the principle for a 1D array.\n",
    "\n",
    "Can you adapt & implement this idea for the case of 2D images?\n",
    "\n",
    "What you have to do:\n",
    "* Implement the function `extract_patches()`. The file `extract_patches.py` provides a starting point.\n",
    "There is also a quick test, to check the correct implementation of this patch extraction.\n",
    "* Afterwards you can include it in the `ImageSegmenter` to use the p x p neighborhood for feature extraction.\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1tYMIkxfDTQ7tYnbfo5C6wUtfOrxRwIiO)\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b70d1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1729168717739,
     "user": {
      "displayName": "IACV-TA-Team",
      "userId": "02056513601283280926"
     },
     "user_tz": -120
    },
    "id": "b2b70d1b",
    "outputId": "3c3df7a5-ab80-472a-aa82-eb76d1238023"
   },
   "outputs": [],
   "source": [
    "from extract_patches import check_patch_extraction, extract_patches\n",
    "\n",
    "check_patch_extraction(extract_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6af274",
   "metadata": {
    "id": "eb6af274"
   },
   "source": [
    "### Evaluate on validation data\n",
    "\n",
    "The performance of most algorithms has a strong dependence on hyper-parameters.\n",
    "In the case of the baseline implementation, these are mainly the number of FG/BG cluster.\n",
    "\n",
    "Can you find hyper-parameters that beat the baseline?\n",
    "\n",
    "You may do it in a trial and error fashion. Alternatively you can do an exhaustive grid search, by looping of hyper-parameters - but that's up to you!\n",
    "\n",
    "Good luck :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055913",
   "metadata": {
    "id": "08055913"
   },
   "outputs": [],
   "source": [
    "segmenter = ImageSegmenter()\n",
    "\n",
    "iou_per_seed, proc_time_per_seed = [], []\n",
    "for seed in [1, 2, 3]:\n",
    "    iou, proc_time = evaluate_segmentation(segmenter, sample_dirs, seed=seed, display=True)\n",
    "    iou_per_seed.append(iou)\n",
    "    proc_time_per_seed.append(proc_time)\n",
    "\n",
    "iou = sum(iou_per_seed) / len(iou_per_seed)\n",
    "proc_time = sum(proc_time_per_seed) / len(proc_time_per_seed)\n",
    "\n",
    "print(f\"Mean IoU: {iou:0.3f} with average time per image of {proc_time:0.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HGMRKhNo0yJx",
   "metadata": {
    "id": "HGMRKhNo0yJx"
   },
   "source": [
    "## Create submission\n",
    "\n",
    "\n",
    "After finishing your implementation, you can run the next cell to generate your submission.\n",
    "We simply copy all relevant files to the submission folder.\n",
    "Download the submission folder as a zip, and upload it to the evaluation server.\n",
    "\n",
    "The evaluation server will run the `ImageSegmenter` with it's default hyper-parameters. So remember to set your optimal hyper-parameters as defaults!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea5f53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1695116987979,
     "user": {
      "displayName": "Georg Brunner",
      "userId": "13715173491527462388"
     },
     "user_tz": -120
    },
    "id": "98ea5f53",
    "outputId": "e75ce9b3-a0ad-4fa2-847c-9af139106fec"
   },
   "outputs": [],
   "source": [
    "out_dir = env_path / 'submission'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "shutil.copyfile(str(env_path / 'kmeans.py'), str(out_dir / 'kmeans.py'))\n",
    "shutil.copyfile(str(env_path / 'extract_patches.py'), str(out_dir / 'extract_patches.py'))\n",
    "shutil.copyfile(str(env_path / 'image_segmenter.py'), str(out_dir / 'image_segmenter.py'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "runtime_attributes": {
    "runtime_version": "2025.07"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
